{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6fb8d5-b646-4a50-846c-c32619544143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import dateutil\n",
    "import shutil\n",
    "from typing import Iterable\n",
    "from pprint import pprint\n",
    "import time\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cloudcatalog\n",
    "import cdflib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51cb06bc-baac-4471-aab4-b89d23845ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms_id = 1\n",
    "EARTH_RADIUS = 6378.14  # km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ae7849-7c7d-452e-a8f8-b298641fe633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progressbar(iterator: Iterable, iter_length: int = None, text: str = None):\n",
    "    \"\"\"\n",
    "    A terminal progress bar.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    iterator: Iterable\n",
    "        The iterable that will be looped over.\n",
    "    iter_length: int\n",
    "        How many items the iterator loop over. If None, will calculate it\n",
    "        using len(iterator).\n",
    "    text: str\n",
    "        Insert an optional text string in the beginning of the progressbar.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        text = ''\n",
    "    else:\n",
    "        text = text + ':'\n",
    "\n",
    "    if iter_length is None:\n",
    "        iter_length = len(iterator)\n",
    "\n",
    "    try:\n",
    "        for i, item in enumerate(iterator):\n",
    "            i += 1  # So we end at 100%. Happy users!\n",
    "            terminal_cols = shutil.get_terminal_size(fallback=(80, 20)).columns\n",
    "            max_cols = int(terminal_cols - len(text) - 10)\n",
    "            # Prevent a crash if the terminal window is narrower then len(text).\n",
    "            if max_cols < 0:\n",
    "                max_cols = 0\n",
    "\n",
    "            percent = round(100 * i / iter_length)\n",
    "            bar = \"#\" * int(max_cols * percent / 100)\n",
    "            print(f'{text} |{bar:<{max_cols}}| {percent}%', end='\\r')\n",
    "            yield item\n",
    "    finally:\n",
    "        print()  # end with a newline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "637e8ed3-2835-4f2d-958b-6ee2f9c3473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open up the global Catalog\n",
    "cr = cloudcatalog.CatalogRegistry()\n",
    "endpoint = cr.get_endpoint(\"GSFC HelioCloud Public Temp\")\n",
    "fr = cloudcatalog.CloudCatalog(endpoint, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83736a2a-0b78-4433-becf-b92d1f43dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgm_catalog_meta = [i for i in fr.catalog['catalog'] if f'mms{mms_id}_fgm_srvy' in i['id']]\n",
    "assert len(fgm_catalog_meta) == 1, f'{len(fgm_catalog_meta)}. MMS{mms_id} FGM catalogs found.'\n",
    "fgm_catalog_meta = fgm_catalog_meta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89bfa414-596c-4441-9065-6c7383bf09f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'mms1_fgm_srvy',\n",
       " 'index': 's3://helio-public/MMS/mms1/fgm/srvy/l2/',\n",
       " 'title': 'mms1/fgm/srvy/l2/',\n",
       " 'start': '2015-06-01T00:00:00Z',\n",
       " 'stop': '2021-12-31T23:59:00Z',\n",
       " 'modification': '2023-03-08T00:00:00Z',\n",
       " 'indextype': 'csv',\n",
       " 'filetype': 'cdf'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgm_catalog_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3451f27c-fde6-40e1-81dd-afd491b83c3b",
   "metadata": {},
   "source": [
    "## Figure out the start and end dates for our for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6e62103-e760-4ed1-b5d0-d5b54fa92cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date=datetime.datetime(2021, 12, 30, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "# -1 because we don't need the UTC timezone letter.\n",
    "start_date = dateutil.parser.parse(fgm_catalog_meta['start'][:-1])\n",
    "\n",
    "save_dir = pathlib.Path(pathlib.Path.home() / 'mms_cs', 'data')\n",
    "ns_path = save_dir / 'mms_ns_crossings.csv'\n",
    "ns_progress_path = save_dir / 'mms_ns_progress.txt'\n",
    "\n",
    "if ns_path.exists() and ns_progress_path.exists():\n",
    "    ns_df = pd.read_csv(ns_path) \n",
    "    start_date = dateutil.parser.parse(ns_progress_path.read_text()) + timedelta(days=1)\n",
    "else:\n",
    "    ns_df = pd.DataFrame()\n",
    "    start_date = dateutil.parser.parse(fgm_catalog_meta['start'][:-1])\n",
    "\n",
    "print(f'{start_date=}')\n",
    "end_date = dateutil.parser.parse(fgm_catalog_meta['stop'][:-1])\n",
    "    \n",
    "dates = [start_date + timedelta(days=i) for i in range((end_date-start_date).days)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e3236-bb82-4f37-b137-e7ab82151bb1",
   "metadata": {},
   "source": [
    "## Neutral sheet crossings\n",
    "Here we calculate neutral sheet crossings using the simple criteria of $B_{x}$ changing sign. Furthermore, we impose the conditions that $r_{x}$ < 0 and $r>6$, filtering to events to times when MMS was on the nightside and beyond the inner magnetosphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2cc0af3-af76-4097-a485-4ca1849ec3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bx_crossings(fgm: cdflib.CDF, mec: cdflib.CDF):\n",
    "    \"\"\"\n",
    "    Calculate the time of Bx crossings, as well as MMS's location at the time.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fgm\n",
    "        The Level 2 FGM survey data\n",
    "    mec\n",
    "        The MEC data\n",
    "    \"\"\"\n",
    "    mms_id = fgm.globalattsget()['Source_name'][-1]\n",
    "    assert isinstance(fgm, cdflib.CDF)\n",
    "    assert isinstance(mec, cdflib.CDF)\n",
    "    data = {}\n",
    "    changed_sign_idx = np.where(\n",
    "                    np.sign(fgm[f'mms{mms_id}_fgm_b_gsm_srvy_l2'][:, 0])[1:] - \\\n",
    "                    np.sign(fgm[f'mms{mms_id}_fgm_b_gsm_srvy_l2'][:, 0])[:-1] != 0\n",
    "                    )[0]\n",
    "    if changed_sign_idx.shape[0] == 0:\n",
    "        data['time'] = np.array([])\n",
    "        return data\n",
    "    \n",
    "    data['time'] = np.array(cdflib.cdfepoch.to_datetime(fgm['epoch']))[changed_sign_idx]\n",
    "    data['bx'] = fgm[f'mms{mms_id}_fgm_b_gsm_srvy_l2'][changed_sign_idx, 0]\n",
    "    data['by'] = fgm[f'mms{mms_id}_fgm_b_gsm_srvy_l2'][changed_sign_idx, 1]\n",
    "    data['bz'] = fgm[f'mms{mms_id}_fgm_b_gsm_srvy_l2'][changed_sign_idx, 2]\n",
    "    data['b'] = np.sqrt(data['bx']**2 + data['by']**2 + data['bz']**2)\n",
    "\n",
    "    mec_times = np.array(cdflib.cdfepoch.to_datetime(mec['epoch']))\n",
    "    changed_sign_idx_mec = -999_999*np.ones_like(changed_sign_idx)\n",
    "    for i, _time in enumerate(data['time']):\n",
    "        changed_sign_idx_mec[i] = np.argmin(np.abs((_time - mec_times)/pd.Timedelta(seconds=1)))\n",
    "    data['rx'] = mec[f'mms{mms_id}_mec_r_gsm'][changed_sign_idx_mec, 0]/EARTH_RADIUS\n",
    "    data['ry'] = mec[f'mms{mms_id}_mec_r_gsm'][changed_sign_idx_mec, 1]/EARTH_RADIUS\n",
    "    data['rz'] = mec[f'mms{mms_id}_mec_r_gsm'][changed_sign_idx_mec, 2]/EARTH_RADIUS\n",
    "    data['r'] = np.sqrt(data['rx']**2 + data['ry']**2 + data['rz']**2)\n",
    "    \n",
    "    idx = np.where((data['r'] > 6) & (data['rx'] < 0))[0]\n",
    "    for key, val in data.items():\n",
    "        data[key] = val[idx]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ead9ae15-ba97-4e22-8bd6-cda51c6a55e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped dates: 0 | run time: 0.0 hours.\n"
     ]
    }
   ],
   "source": [
    "skipped_dates = []\n",
    "start_time = time.time()\n",
    "\n",
    "for _start_date, _end_date in progressbar(zip(dates[:-1], dates[1:]), iter_length=len(dates)-1):\n",
    "    _start_date = _start_date.isoformat()\n",
    "    _end_date = _end_date.isoformat()\n",
    "    fgm_cat = fr.request_cloud_catalog(f'mms{mms_id}_fgm_srvy', start_date=_start_date, stop_date=_end_date)\n",
    "    mec_cat = fr.request_cloud_catalog(f'mms{mms_id}_mec_srvy_epht89d', start_date=_start_date, stop_date=_end_date)\n",
    "    \n",
    "    if len(fgm_cat['datakey']) == 0:  # No FGM files.\n",
    "        skipped_dates.append(_start_date)\n",
    "        continue\n",
    "    fgm = cdflib.CDF(fgm_cat['datakey'].values[0])\n",
    "    mec = cdflib.CDF(mec_cat['datakey'].values[0])\n",
    "    data = calc_bx_crossings(fgm, mec)\n",
    "    if data['time'].shape[0] == 0:\n",
    "        ns_progress_path.write_text(_start_date)\n",
    "        continue\n",
    "    ns_df = pd.concat((ns_df, pd.DataFrame(data))).round(decimals=2)\n",
    "    ns_df.to_csv(ns_path, index=False)\n",
    "    ns_progress_path.write_text(_start_date)\n",
    "    \n",
    "print(f'Skipped dates: {len(skipped_dates)} | run time: {(time.time() - start_time)//3600} hours.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
